{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NL_SpaCy_ML_Classifier_for_Waste_Data_Augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "A_nJbg_AabzL",
        "1kRKYNjnahwE",
        "0WRlhwvUacc9",
        "GPu5uHNrjQAZ",
        "o78_Ruskc9O8",
        "sRNnajFQ7w__",
        "we8aDA-Tgjx9",
        "Q4qJsTC9i9ko",
        "VenFHCmcrAYr",
        "UKWlXGY8udV6"
      ],
      "authorship_tag": "ABX9TyOU4uUi9An+JjIWFicEHbwu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yolantele/ML-data-clasifier/blob/master/NL_SpaCy_ML_Classifier_for_Waste_Data_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3PcxBlkrRON",
        "colab_type": "text"
      },
      "source": [
        "# **Dutch Waste Data Classification and Augmentation** \n",
        "\n",
        "Performs text analysis operations with spaCy and  builds machine learning model with scikit-learn\n",
        "\n",
        "\n",
        "scikit-learn :\n",
        "https://scikit-learn.org/stable/\n",
        "\n",
        "spaCy Language Models:\n",
        "https://spacy.io/usage/models\n",
        "\n",
        "scikit-learn + Spacy : \n",
        "https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/\n",
        "\n",
        "Eural Code reference: \n",
        "https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:02000D0532-20150601\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0MIMTSkPAN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GchVo49oPHvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d0af6b7b-31a6-4769-b329-c331df26925d"
      },
      "source": [
        "# mount data from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTRIFjFaPbf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U spacy\n",
        "!pip install pandas\n",
        "!python -m spacy download nl_core_news_md"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se5WawQnZ-p_",
        "colab_type": "text"
      },
      "source": [
        "## **Loading Languages model and Data Frames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxLC2X13Qw7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "from spacy.lang.nl import Dutch\n",
        "import nl_core_news_md\n",
        "spacy.prefer_gpu()\n",
        "\n",
        "nlp = nl_core_news_md.load #medium size lang model (smae results as large size lanf model)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L324D-Gql23q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "89054bdc-a6c7-4ff4-e8e5-92036ec7d300"
      },
      "source": [
        "path = '/content/drive/My Drive/data/'\n",
        "\n",
        "# train data frames:\n",
        "all_data = pd.read_csv(path + '/nlData.csv')\n",
        "\n",
        "\n",
        "# test data frames:\n",
        "materials_test = pd.read_csv(path + '/nlWithoutMaterialData.csv')\n",
        "\n",
        "# set data frame: \n",
        "df = all_data\n",
        "\n",
        "\n",
        "df.shape\n",
        "df.info()\n",
        "df.head()\n"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5848 entries, 0 to 5847\n",
            "Data columns (total 27 columns):\n",
            " #   Column            Non-Null Count  Dtype  \n",
            "---  ------            --------------  -----  \n",
            " 0   reason            45 non-null     object \n",
            " 1   origin            130 non-null    object \n",
            " 2   color             61 non-null     object \n",
            " 3   state             1098 non-null   object \n",
            " 4   size              190 non-null    object \n",
            " 5   consistency       5390 non-null   object \n",
            " 6   otherCode         973 non-null    object \n",
            " 7   material4         28 non-null     object \n",
            " 8   material3         490 non-null    object \n",
            " 9   material2         986 non-null    object \n",
            " 10  material          3696 non-null   object \n",
            " 11  mType             946 non-null    object \n",
            " 12  composite2        56 non-null     object \n",
            " 13  composite1        2793 non-null   object \n",
            " 14  cType             354 non-null    object \n",
            " 15  indirectProduct   3683 non-null   object \n",
            " 16  directProduct     923 non-null    object \n",
            " 17  pType             66 non-null     object \n",
            " 18  mixedOrPure       4796 non-null   object \n",
            " 19  cleanOrDirty      971 non-null    object \n",
            " 20  euralDescription  5502 non-null   object \n",
            " 21  euralCode         5848 non-null   object \n",
            " 22  description       5848 non-null   object \n",
            " 23  Unnamed: 23       0 non-null      float64\n",
            " 24  Unnamed: 24       0 non-null      float64\n",
            " 25  Unnamed: 25       0 non-null      float64\n",
            " 26  Unnamed: 26       0 non-null      float64\n",
            "dtypes: float64(4), object(23)\n",
            "memory usage: 1.2+ MB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reason</th>\n",
              "      <th>origin</th>\n",
              "      <th>color</th>\n",
              "      <th>state</th>\n",
              "      <th>size</th>\n",
              "      <th>consistency</th>\n",
              "      <th>otherCode</th>\n",
              "      <th>material4</th>\n",
              "      <th>material3</th>\n",
              "      <th>material2</th>\n",
              "      <th>material</th>\n",
              "      <th>mType</th>\n",
              "      <th>composite2</th>\n",
              "      <th>composite1</th>\n",
              "      <th>cType</th>\n",
              "      <th>indirectProduct</th>\n",
              "      <th>directProduct</th>\n",
              "      <th>pType</th>\n",
              "      <th>mixedOrPure</th>\n",
              "      <th>cleanOrDirty</th>\n",
              "      <th>euralDescription</th>\n",
              "      <th>euralCode</th>\n",
              "      <th>description</th>\n",
              "      <th>Unnamed: 23</th>\n",
              "      <th>Unnamed: 24</th>\n",
              "      <th>Unnamed: 25</th>\n",
              "      <th>Unnamed: 26</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>slib van wassen en schoonmaken</td>\n",
              "      <td>020101</td>\n",
              "      <td>SLIB VAN WASSEN EN SCHOONMAKEN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>afgekeurd</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vast</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>organisch materiaal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GFT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GFT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gemengd</td>\n",
              "      <td>NaN</td>\n",
              "      <td>afval van dierlijke weefsels</td>\n",
              "      <td>020102</td>\n",
              "      <td>GFT Afgekeurd</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vast</td>\n",
              "      <td>categorie 3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>organisch materiaal</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GFT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>GFT</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>puur</td>\n",
              "      <td>NaN</td>\n",
              "      <td>afval van dierlijke weefsels</td>\n",
              "      <td>020102</td>\n",
              "      <td>GFT Categorie 3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>afval van plantaardige weefsels</td>\n",
              "      <td>020103</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vast</td>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hout</td>\n",
              "      <td>stobben</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hout</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>puur</td>\n",
              "      <td>NaN</td>\n",
              "      <td>afval van plantaardige weefsels</td>\n",
              "      <td>020103</td>\n",
              "      <td>200 Boomstobben</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      reason origin color  ... Unnamed: 24 Unnamed: 25 Unnamed: 26\n",
              "0        NaN    NaN   NaN  ...         NaN         NaN         NaN\n",
              "1  afgekeurd    NaN   NaN  ...         NaN         NaN         NaN\n",
              "2        NaN    NaN   NaN  ...         NaN         NaN         NaN\n",
              "3        NaN    NaN   NaN  ...         NaN         NaN         NaN\n",
              "4        NaN    NaN   NaN  ...         NaN         NaN         NaN\n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPOLLyVRzcQ9",
        "colab_type": "text"
      },
      "source": [
        "## **Tokening the Data With spaCy**\n",
        "\n",
        "creating a custom tokenizer function using spaCy to automatically strip unnecesarry information like stopwords and punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDWKUU8RvJz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.lang.nl.stop_words import STOP_WORDS\n",
        "\n",
        "\n",
        "parser = Dutch()\n",
        "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "stopwords = STOP_WORDS\n",
        "# stopwords = [] # in some cases stopwords help (increase accuracy by 1%)\n",
        "\n",
        "def spacy_tokenize(sentence):\n",
        "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
        "    sentence = sentence.strip().lower()\n",
        "    mytokens = parser(sentence)\n",
        "\n",
        "    # Lemmatizing each token and converting each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens  ]\n",
        "\n",
        "    # Removing stop words\n",
        "    mytokens = [ word for word in mytokens if word not in punctuations and word not in stopwords]\n",
        "\n",
        "    # return preprocessed list of tokens\n",
        "    return mytokens\n"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj7q5mGz0V6Q",
        "colab_type": "text"
      },
      "source": [
        "###**Vectorization Feature Engineering, TF-IDF, Bag of Words and N-grams**\n",
        "\n",
        "Classifying text we end up with text snippets with their respective labels. But in machine learning model we need to convert into numeric representation (vector coordinates)\n",
        "\n",
        "- **TF-IDF -Term Frequency-Inverse Document Frequency**- simply a way of normalizing our Bag of Words(BoW) by looking at each word’s frequency in comparison to the document frequency.\n",
        "\n",
        "- **N-grams** - combinations of adjacent words in a given text. For example \"who will win\"\n",
        " 1. when n = 1, becomes \"who\", \"will\", \"win\",\n",
        " 2. when n = 2 , becomes \"who will\", \"will win\" etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8vNowrk0WUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "\n",
        "bow_vector = CountVectorizer(tokenizer=spacy_tokenize, ngram_range=(1,1))\n",
        "\n",
        "tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenize)\n",
        "\n",
        "# print(bow_vector)\n",
        "# print(tfidf_vector)"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYHmZbUqv_3i",
        "colab_type": "text"
      },
      "source": [
        "## **Splitting The Data into Training and Validation Sets**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_nJbg_AabzL",
        "colab_type": "text"
      },
      "source": [
        "### material classiciation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d4AVLzEv_Cb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "251e55ef-5f66-42b9-b953-15fe10fd315e"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = df[df['material'].notna()]\n",
        "\n",
        "X = df['description'] # the features we want to analyze\n",
        "ylabels = df['material'] # the labels, or answers, we want to test against\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3)\n",
        "\n",
        "print(X)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1                                           GFT Afgekeurd\n",
            "2                                         GFT Categorie 3\n",
            "4                                         200 Boomstobben\n",
            "5                                                BERMGRAS\n",
            "6                          BLAUWMAANZAAD TER VERNIETIGING\n",
            "                              ...                        \n",
            "5838                                          fruitresten\n",
            "5839                             gft vloeibare reststrome\n",
            "5840            consumptie ongeschikt mat. (palmvetzuren)\n",
            "5842                                              zetmeel\n",
            "5845    voedings-en genotmiddelen ongeschikt voor cons...\n",
            "Name: description, Length: 3696, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kRKYNjnahwE",
        "colab_type": "text"
      },
      "source": [
        "### mixedOrPure classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48JEgVVGamer",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1e21354d-ae6e-4eda-8a02-8f1f7072821c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "df = df[df['mixedOrPure'].notna()]\n",
        "\n",
        "X = df['description'] # the features we want to analyze\n",
        "ylabels = df['mixedOrPure'] # the labels, or answers, we want to test against\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3)\n",
        "\n",
        "print(X)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1                                   GFT Afgekeurd\n",
            "2                                 GFT Categorie 3\n",
            "4                                 200 Boomstobben\n",
            "5                                        BERMGRAS\n",
            "6                  BLAUWMAANZAAD TER VERNIETIGING\n",
            "                          ...                    \n",
            "5841    sediment uit plantaardige olie & bijprod.\n",
            "5842                                      zetmeel\n",
            "5843                             beddingmateriaal\n",
            "5844                                bedding afval\n",
            "5846           000 rum ongeschikt voor consumptie\n",
            "Name: description, Length: 4796, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WRlhwvUacc9",
        "colab_type": "text"
      },
      "source": [
        "### consistency classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGzzKaqYahCl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "534ba13d-9b12-4f9f-9b61-ef0f4169c006"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "df = df[df['consistency'].notna()]\n",
        "\n",
        "X = df['description'] # the features we want to analyze\n",
        "ylabels = df['consistency'] # the labels, or answers, we want to test against\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3)\n",
        "\n",
        "print(X)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1                                   GFT Afgekeurd\n",
            "2                                 GFT Categorie 3\n",
            "4                                 200 Boomstobben\n",
            "5                                        BERMGRAS\n",
            "6                  BLAUWMAANZAAD TER VERNIETIGING\n",
            "                          ...                    \n",
            "5841    sediment uit plantaardige olie & bijprod.\n",
            "5842                                      zetmeel\n",
            "5843                             beddingmateriaal\n",
            "5844                                bedding afval\n",
            "5846           000 rum ongeschikt voor consumptie\n",
            "Name: description, Length: 5390, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPu5uHNrjQAZ",
        "colab_type": "text"
      },
      "source": [
        "### cleanOrDirty classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LI0boqY2j2FZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "bc9e8016-acae-459d-c49b-d8cfa469b8e0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "df = df[df['cleanOrDirty'].notna()]\n",
        "\n",
        "X = df['description'] # the features we want to analyze\n",
        "ylabels = df['cleanOrDirty'] # the labels, or answers, we want to test against\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3)\n",
        "\n",
        "print(X)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11                 Gras vervuild met Japanse Duizendknoop\n",
            "12                    Groenafval met Japanse duizendknoop\n",
            "13                Groenafval vervuild met invasieve exoot\n",
            "14                  Rozenafval verontreinigd met steenwol\n",
            "41                           431 Organisch afval vervuild\n",
            "                              ...                        \n",
            "5805                          grond met zuur (drugsafval)\n",
            "5806                                   verontreinigd zand\n",
            "5816                          selectief verwijderd asbest\n",
            "5817    metaalafval dat met gevaarlijke stoffen is ver...\n",
            "5818                            metaalafval verontreinigd\n",
            "Name: description, Length: 971, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o78_Ruskc9O8",
        "colab_type": "text"
      },
      "source": [
        "### directProduct classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8IDgSK5dHxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3f02ee3b-2dba-4f5e-c785-959cb22dec6d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "df = df[df['directProduct'].notna()]\n",
        "\n",
        "X = df['description'] # the features we want to analyze\n",
        "ylabels = df['directProduct'] # the labels, or answers, we want to test against\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3)\n",
        "\n",
        "print(X)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46                                  Digestaat plantaardig\n",
            "47                                 VOT/VGW-Monsanto/zaden\n",
            "48                           VOT/Zaden/Mil.Expr.-Monsanto\n",
            "58                                 PVC - buizen/profielen\n",
            "75                                   Bestrijdingsmiddelen\n",
            "                              ...                        \n",
            "5843                                     beddingmateriaal\n",
            "5844                                        bedding afval\n",
            "5845    voedings-en genotmiddelen ongeschikt voor cons...\n",
            "5846                   000 rum ongeschikt voor consumptie\n",
            "5847                         afval van dierlijke weefsels\n",
            "Name: description, Length: 923, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRNnajFQ7w__",
        "colab_type": "text"
      },
      "source": [
        "### indirectProduct Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40I8pLd371L8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "08132d3e-67c2-41fa-91de-877741a275b3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "df = df[df['indirectProduct'].notna()]\n",
        "\n",
        "X = df['description'] # the features we want to analyze\n",
        "ylabels = df['indirectProduct'] # the labels, or answers, we want to test against\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3)\n",
        "\n",
        "print(X)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1                                           GFT Afgekeurd\n",
            "2                                         GFT Categorie 3\n",
            "4                                         200 Boomstobben\n",
            "5                                                BERMGRAS\n",
            "6                          BLAUWMAANZAAD TER VERNIETIGING\n",
            "                              ...                        \n",
            "5843                                     beddingmateriaal\n",
            "5844                                        bedding afval\n",
            "5845    voedings-en genotmiddelen ongeschikt voor cons...\n",
            "5846                   000 rum ongeschikt voor consumptie\n",
            "5847                         afval van dierlijke weefsels\n",
            "Name: description, Length: 3683, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we8aDA-Tgjx9",
        "colab_type": "text"
      },
      "source": [
        "### cType classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVDMLgeagmnm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "3c086fb4-780f-401d-fde7-02bc8f9ed456"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = df[df['cType'].notna()]\n",
        "\n",
        "X = df['description'] # the features we want to analyze\n",
        "ylabels = df['cType'] # the labels, or answers, we want to test against\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3)\n",
        "\n",
        "print(X)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "119            Uitgepakte voedingsmiddelen supermarktmix\n",
            "281                              Verpakte levensmiddelen\n",
            "301       Consumptie ongeschikt mat. (marinades, sauzen)\n",
            "331     02.03.05 - Afvalwaterslib plantaardige oorsprong\n",
            "467                                           papierslib\n",
            "                              ...                       \n",
            "5769                                       bentonietslib\n",
            "5777                                        puin gemengd\n",
            "5780                      gemengd- en containerpuin < 70\n",
            "5830                          onges. huishoud batterijen\n",
            "5832                             fietsbatterijen gemengd\n",
            "Name: description, Length: 354, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4qJsTC9i9ko",
        "colab_type": "text"
      },
      "source": [
        "### composite1 classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RCQSJ3FjBEY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "bc022a90-6a7d-43cc-9dac-2bc5b46b21ad"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = df[df['composite1'].notna()]\n",
        "\n",
        "X = df['description'] # the features we want to analyze\n",
        "ylabels = df['composite1'] # the labels, or answers, we want to test against\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3)\n",
        "\n",
        "print(X)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1                                           GFT Afgekeurd\n",
            "2                                         GFT Categorie 3\n",
            "11                 Gras vervuild met Japanse Duizendknoop\n",
            "14                  Rozenafval verontreinigd met steenwol\n",
            "16                         5430 perliet / organisch afval\n",
            "                              ...                        \n",
            "5834                                    wit- en bruingoed\n",
            "5835                                industrieel slib (ba)\n",
            "5836    voedings en genotmiddelen ongeschikt voor cons...\n",
            "5839                             gft vloeibare reststrome\n",
            "5841            sediment uit plantaardige olie & bijprod.\n",
            "Name: description, Length: 2793, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VenFHCmcrAYr",
        "colab_type": "text"
      },
      "source": [
        "### state classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDGwSPLUrEbr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "ecac1521-8171-49ee-8c94-074e6ea5319b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = df[df['state'].notna()]\n",
        "\n",
        "X = df['description'] # the features we want to analyze\n",
        "ylabels = df['state'] # the labels, or answers, we want to test against\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3)\n",
        "\n",
        "print(X)\n",
        "print(ylabels)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15          5430 organisch afval ongehakse\n",
            "36                      Meloenen in netjes\n",
            "54      1407 Tuinbouwfolie / landbouwfolie\n",
            "55                           Landbouwfolie\n",
            "76              Bestrijdingsmiddelen (kvp)\n",
            "                       ...                \n",
            "5792             3240 puin gemengd < 70 cm\n",
            "5799               verontreinigd puin fijn\n",
            "5802             verontreinigde grond/puin\n",
            "5812                         plastic draad\n",
            "5819                   folies/kunststoffen\n",
            "Name: description, Length: 1098, dtype: object\n",
            "15          ongehakseld\n",
            "36            in netjes\n",
            "54                folie\n",
            "55                folie\n",
            "76      kleinverpakking\n",
            "             ...       \n",
            "5792               puin\n",
            "5799         puin, fijn\n",
            "5802               puin\n",
            "5812              draad\n",
            "5819              folie\n",
            "Name: state, Length: 1098, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mXhEsj_ljFJ",
        "colab_type": "text"
      },
      "source": [
        "### mType classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR9ExN12lp1V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "df3783bb-ab16-4156-b5dc-e9f161db11f1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = df[df['mType'].notna()]\n",
        "\n",
        "X = df['description'] # the features we want to analyze\n",
        "ylabels = df['mType'] # the labels, or answers, we want to test against\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3)\n",
        "\n",
        "print(X)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4                                         200 Boomstobben\n",
            "5                                                BERMGRAS\n",
            "6                          BLAUWMAANZAAD TER VERNIETIGING\n",
            "7                                             Bloembollen\n",
            "8                                  Boomstronken (stobben)\n",
            "                              ...                        \n",
            "5810              > 28% koper-pit teerhoudende grondkabel\n",
            "5826    geslagen aluminium, oude en nieuwe aluminium p...\n",
            "5837                                      plantaardig vet\n",
            "5838                                          fruitresten\n",
            "5840            consumptie ongeschikt mat. (palmvetzuren)\n",
            "Name: description, Length: 946, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKWlXGY8udV6",
        "colab_type": "text"
      },
      "source": [
        "### otherCode classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHYK0NwjuhsG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bcafbc83-44df-4ef6-88f8-b2b5a9cb7089"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = df[df['otherCode'].notna()]\n",
        "\n",
        "X = df['description'] # the features we want to analyze\n",
        "ylabels = df['otherCode'] # the labels, or answers, we want to test against\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3)\n",
        "\n",
        "print(X)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2                                         GFT Categorie 3\n",
            "3                                                       2\n",
            "4                                         200 Boomstobben\n",
            "11                 Gras vervuild met Japanse Duizendknoop\n",
            "15                         5430 organisch afval ongehakse\n",
            "                              ...                        \n",
            "5786                                        1480 dakgrind\n",
            "5789                        3242 puin mineraal vervuild <\n",
            "5792                            3240 puin gemengd < 70 cm\n",
            "5816                          selectief verwijderd asbest\n",
            "5826    geslagen aluminium, oude en nieuwe aluminium p...\n",
            "Name: description, Length: 973, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs546SLByRfT",
        "colab_type": "text"
      },
      "source": [
        "## **Creating a Pipeline and Generating the Model**\n",
        "\n",
        "###we’ll create a pipeline with three components: a **cleaner, a vectorizer, and a classifier**. \n",
        "\n",
        "- The cleaner uses our predictors class object to clean and preprocess the text. \n",
        "\n",
        "- The vectorizer uses countvector objects to create the bag of words matrix for our text. \n",
        "\n",
        "- The classifier is an object that performs the logistic regression to classify the sentiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAiqgGLrOiwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Custom transformer using spaCy\n",
        "class predictors(TransformerMixin):\n",
        "    def transform(self, X, **transform_params):\n",
        "        # Cleaning Text\n",
        "        return [clean_text(text) for text in X]\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {}\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    # Removing spaces and converting text into lowercase\n",
        "    return text.strip().lower()"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0iorejbyVs6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "d6a6b8cd-ca25-4b19-a662-026955935ba8"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Creating Logistic Regression Classifier\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "# Create pipeline using Bag of Words (BoW)\n",
        "model = Pipeline([(\"cleaner\", predictors()),\n",
        "                 ('vectorizer', bow_vector),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# model generation\n",
        "model.fit(X_train,y_train)"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('cleaner', <__main__.predictors object at 0x7f36242d9dd8>),\n",
              "                ('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 t...\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function spacy_tokenize at 0x7f3624a710d0>,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf24RclNTpUE",
        "colab_type": "text"
      },
      "source": [
        "### **Model Predictions - Classifications**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzuGqju6zSjW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "33116576-1866-43b4-b073-e026a1826074"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "row = 3\n",
        "\n",
        "# Predicting for a test dataset\n",
        "predicted = model.predict(X_test)\n",
        "n = 0\n",
        "print('Using validation set:')\n",
        "print('predicted is ----->', predicted[0 + n], '(descr: ', X_test.iloc[0 + n], ')')\n",
        "print('predicted is ----->', predicted[1 + n], '(descr: ', X_test.iloc[1 + n], ')')\n",
        "print('predicted is ----->', predicted[2 + n], '(descr: ', X_test.iloc[2 + n], ')')\n",
        "print('predicted is ----->', predicted[3 + n], '(descr: ', X_test.iloc[3 + n], ')')\n",
        "# print('predicted is ----->', predicted[4 + n], '(descr: ', X_test.iloc[4 + n], ')')\n",
        "print('predicted is ----->', predicted[5 + n], '(descr: ', X_test.iloc[5 + n], ')')\n",
        "print('predicted is ----->', predicted[6 + n], '(descr: ', X_test.iloc[6 + n], ')')\n",
        "print('predicted is ----->', predicted[7 + n], '(descr: ', X_test.iloc[7 + n], ')')\n",
        "print('predicted is ----->', predicted[8 + n], '(descr: ', X_test.iloc[8 + n], ')')\n",
        "\n",
        "\n",
        "# predict using unclassified set\n",
        "pred = model.predict(materials_test)\n",
        "print('')\n",
        "print('Using unclassified set:')\n",
        "print('predicted is ----->', pred[0 + n], '(descr: ', materials_test.iloc[0 + n].description, ')')\n",
        "print('predicted is ----->', pred[1 + n], '(descr: ', materials_test.iloc[1 + n].description, ')')\n",
        "print('predicted is ----->', pred[2 + n], '(descr: ', materials_test.iloc[2 + n].description, ')')\n",
        "print('predicted is ----->', pred[3 + n], '(descr: ', materials_test.iloc[3 + n].description, ')')\n",
        "# print('predicted is ----->', pred[4 + n], '(descr: ', materials_test.iloc[4 + n].description, ')')\n",
        "print('predicted is ----->', pred[5 + n], '(descr: ', materials_test.iloc[5 + n].description, ')')\n",
        "print('predicted is ----->', pred[6 + n], '(descr: ', materials_test.iloc[6 + n].description, ')')\n",
        "print('predicted is ----->', pred[7 + n], '(descr: ', materials_test.iloc[7 + n].description, ')')\n",
        "print('predicted is ----->', pred[8 + n], '(descr: ', materials_test.iloc[8 + n].description, ')')\n",
        "\n",
        "\n",
        "# print(model.predict(materials_test)[row])\n",
        "\n"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using validation set:\n",
            "predicted is -----> B (descr:  B-Hout, J. Blokdijk en Zn )\n",
            "predicted is -----> takken (descr:  Takken,Stronken,Stamhout )\n",
            "predicted is -----> takken (descr:  bananen in dozen, verwerkt onder toezicht klant )\n",
            "predicted is -----> B (descr:  Hout (A   B Kwaliteit) )\n",
            "predicted is -----> bont (descr:  bont papier, niet route )\n",
            "predicted is -----> B (descr:  I B-HOUT )\n",
            "predicted is -----> B (descr:  HOUT A-KWALITEIT )\n",
            "predicted is -----> non-ferro (descr:  Non-ferro metalen )\n",
            "\n",
            "Using unclassified set:\n",
            "predicted is -----> takken (descr:  SLIB VAN WASSEN EN SCHOONMAKEN )\n",
            "predicted is -----> takken (descr:  2 )\n",
            "predicted is -----> takken (descr:  ? )\n",
            "predicted is -----> takken (descr:  Niet onder 170503 vallende grond en stenen )\n",
            "predicted is -----> takken (descr:  agrochemisch afval dat gevaarlijke stoffen bevat )\n",
            "predicted is -----> takken (descr:  agrochemisch afval dat gevaarlijke stoffen bevat ( )\n",
            "predicted is -----> takken (descr:  niet onder 02 01 08 vallend agrochemisch afval )\n",
            "predicted is -----> takken (descr:  Bedding afval )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cey26VlblQIA",
        "colab_type": "text"
      },
      "source": [
        "### **Model Accuracy Reports**\n",
        "\n",
        "**Accuracy** refers to the percentage of the total predictions our model makes that are completely correct.\n",
        "\n",
        "**Precision** describes the ratio of true positives to true positives plus false positives in our predictions.\n",
        "\n",
        "**Recall** describes the ratio of true positives to true positives plus false negatives in our predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DkzvWsQ0fTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model Accuracy Reports\n",
        "\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, predicted ))\n",
        "print(\"Precision:\",metrics.precision_score(y_test, predicted, average='weighted'))\n",
        "print(\"Recall:\",metrics.recall_score(y_test, predicted, average='weighted'))\n",
        "print( metrics.classification_report(y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKZVwKfRB2_s",
        "colab_type": "text"
      },
      "source": [
        "### **Plotting the Classification Outcomes (description and material dependencies)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80cYKSKZ6buv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = materials_test\n",
        "\n",
        "#chosen column field option\n",
        "chosen_material = 'slakken'\n",
        "chosen_mixedOrPure = 'puur'\n",
        "chosen_consistency = 'vast'\n",
        "chosen_cleanOrDirty = 'vervuild'\n",
        "chosen_indirectProduct = 'slib'\n",
        "\n",
        "# set graph: \n",
        "outcome = chosen_indirectProduct\n",
        "x_axis = 'indirectProduct'\n",
        "x_data = df.indirectProduct\n",
        "\n",
        "data = df.head(120).loc[x_data ==outcome]\n",
        "sns.set_style('ticks')\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(1, 15)\n",
        "sns.regplot(x=x_axis, y='description', data=data, ax=ax)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y09ArjcybW_m",
        "colab_type": "text"
      },
      "source": [
        "### **Save the Trained Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3If8bcW4__7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "# save the model to disk\n",
        "name = 'nl_mType_classification_model.sav'\n",
        "filename = path + name\n",
        "pickle.dump(model, open(filename, 'wb'))\n",
        " "
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBq2mTdS_VIV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "7cf016d0-8663-4261-efec-f42367ac43b1"
      },
      "source": [
        "#load models\n",
        "cType_name = 'nl_c_type_classification_model.sav'\n",
        "cleanOrDirty_name = 'nl_clean_or_dirty_classification_model.sav'\n",
        "consistency_name = 'nl_consistency_classification_model.sav'\n",
        "composite1_name = 'nl_composite1_classification_model.sav'\n",
        "directProduct_name = 'nl_direct_product_classification_model.sav'\n",
        "indirectProduct_name = 'nl_indirect_product_classification_model.sav'\n",
        "material_name = 'nl_material_classification_model.sav'\n",
        "mixedOrPure_name = 'nl_mixed_or_pure_classification_model.sav'\n",
        "mType_name = 'nl_mType_classification_model.sav'\n",
        "otherCode_name = 'nl_other_code_classification_model.sav'\n",
        "state_name = 'nl_state_classification_model.sav'\n",
        "\n",
        "state_model = pickle.load(open(path + state_name, 'rb'))\n",
        "state_result = state_model.score(X_test, y_test)\n",
        "\n",
        "cType_model = pickle.load(open(path + cType_name, 'rb'))\n",
        "cType_result = cType_model.score(X_test, y_test)\n",
        "\n",
        "cleanOrDirty_model = pickle.load(open(path + cleanOrDirty_name, 'rb'))\n",
        "cleanOrDirty_result = cleanOrDirty_model.score(X_test, y_test)\n",
        "\n",
        "consistency_model = pickle.load(open(path + consistency_name, 'rb'))\n",
        "consistency_result = consistency_model.score(X_test, y_test)\n",
        "\n",
        "composite1_model = pickle.load(open(path + composite1_name, 'rb'))\n",
        "composite1_result = composite1_model.score(X_test, y_test)\n",
        "\n",
        "directProduct_model = pickle.load(open(path + directProduct_name, 'rb'))\n",
        "directProduct_result = directProduct_model.score(X_test, y_test)\n",
        "\n",
        "indirectProduct_model = pickle.load(open(path + indirectProduct_name, 'rb'))\n",
        "indirectProduct_result = indirectProduct_model.score(X_test, y_test)\n",
        "\n",
        "material_model = pickle.load(open(path + material_name, 'rb'))\n",
        "material_result = material_model.score(X_test, y_test)\n",
        "\n",
        "mixedOrPure_model = pickle.load(open(path + mixedOrPure_name, 'rb'))\n",
        "mixedOrPure_result = mixedOrPure_model.score(X_test, y_test)\n",
        "\n",
        "mType_model = pickle.load(open(path + mType_name, 'rb'))\n",
        "mType_result = mType_model.score(X_test, y_test)\n",
        "\n",
        "otherCode_model = pickle.load(open(path + otherCode_name, 'rb'))\n",
        "otherCode_result = otherCode_model.score(X_test, y_test)\n",
        "\n",
        "\n",
        "#models' classifications \n",
        "# overal_score = _model.score(X_test, y_test)\n",
        "row = 7\n",
        "\n",
        "def print_classification_results(row=0, with_accuracy=False):\n",
        "  print('row', row)\n",
        "  print( 'description is --->', X_test.iloc[row])\n",
        "  print( 'cType ------------>', cType_model.predict(X_test)[row], '(OMS - overal model score: 0.40)' if with_accuracy else '')\n",
        "  print( 'clean or dirty --->', cleanOrDirty_model.predict(X_test)[row], '(OMS: 0.79)' if with_accuracy else '')\n",
        "  print( 'consistency ------>', consistency_model.predict(X_test)[row], '(OMS: 0.96)' if with_accuracy else '')\n",
        "  print( 'composite 1 ------>', composite1_model.predict(X_test)[row], '(OMS: 0.78)' if with_accuracy else '')\n",
        "  print( 'direct product --->', directProduct_model.predict(X_test)[row], '(OMS: 0.71)' if with_accuracy else '')\n",
        "  print( 'indirect product ->', indirectProduct_model.predict(X_test)[row],'(OMS: 0.27)' if with_accuracy else '')\n",
        "  print( 'material --------->', material_model.predict(X_test)[row], '(OMS: 0.85)'if with_accuracy else '')\n",
        "  print( 'state ------------>', state_model.predict(X_test)[row], '(OMS: 0.82)'if with_accuracy else '')\n",
        "  print( 'mixed or pure ---->', mixedOrPure_model.predict(X_test)[row],'OMS: 0.86)'if with_accuracy else '')\n",
        "  print( 'm type ----------->', mType_model.predict(X_test)[row],'(OMS: 0.54)'if with_accuracy else '')\n",
        "  print( 'other code ------->', otherCode_model.predict(X_test)[row], '(OMS: 0.44)'if with_accuracy else '')\n",
        "  print('')\n",
        "\n",
        "\n",
        "print_classification_results(row+1, with_accuracy=True)\n",
        "print_classification_results(row+2)\n",
        "print_classification_results(row+3)"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "row 8\n",
            "description is ---> Non-ferro metalen\n",
            "cType ------------> teerhoudend (OMS - overal model score: 0.40)\n",
            "clean or dirty ---> vervuild (OMS: 0.79)\n",
            "consistency ------> vast (OMS: 0.96)\n",
            "composite 1 ------> metalen (OMS: 0.78)\n",
            "direct product ---> 0 (OMS: 0.71)\n",
            "indirect product -> non-ferro (OMS: 0.27)\n",
            "material ---------> metalen (OMS: 0.85)\n",
            "state ------------> puin (OMS: 0.82)\n",
            "mixed or pure ----> gemengd OMS: 0.86)\n",
            "m type -----------> non-ferro (OMS: 0.54)\n",
            "other code -------> 9340 (OMS: 0.44)\n",
            "\n",
            "row 9\n",
            "description is ---> extr reinigbare grond (in)\n",
            "cType ------------> teerhoudend \n",
            "clean or dirty ---> vervuild \n",
            "consistency ------> vast \n",
            "composite 1 ------> composiet \n",
            "direct product ---> grond \n",
            "indirect product -> composiet \n",
            "material ---------> grond \n",
            "state ------------> puin \n",
            "mixed or pure ----> gemengd \n",
            "m type -----------> extractief reinigbaar \n",
            "other code -------> niet toepasbaar \n",
            "\n",
            "row 10\n",
            "description is ---> Klei niet toepasbaar\n",
            "cType ------------> teerhoudend \n",
            "clean or dirty ---> vervuild \n",
            "consistency ------> vast \n",
            "composite 1 ------> composiet \n",
            "direct product ---> 0 \n",
            "indirect product -> composiet \n",
            "material ---------> grond \n",
            "state ------------> puin \n",
            "mixed or pure ----> gemengd \n",
            "m type -----------> kleigrond \n",
            "other code -------> niet toepasbaar \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}