{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpaCy-ML-Classifier-for-Waste-Data-Augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPWw/ehrLy/rvHxOesK+jwj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yolantele/ML-data-clasifier/blob/master/SpaCy_ML_Classifier_for_Waste_Data_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US3U82Q2Oq28",
        "colab_type": "text"
      },
      "source": [
        "####SpaCy_ML_Classifier_for_Waste_Data_Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0MIMTSkPAN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GchVo49oPHvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a6d99c65-ce57-4a83-85b4-01ffdae7f144"
      },
      "source": [
        "# mount data from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/My Drive/data/'\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTRIFjFaPbf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U spacy==2.2.2\n",
        "!pip install pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxLC2X13Qw7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import pandas as pd\n",
        "from spacy.lang.en import English\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "\n",
        "\n",
        "# References:\n",
        "# https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/\n",
        "\n",
        "spacy.prefer_gpu()\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L324D-Gql23q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "3299585d-3c57-4d80-cc20-5dc6864d386e"
      },
      "source": [
        "materials = pd.read_csv(path + '/enMaterialData.csv')\n",
        "# or use test data frame where material field is empty\n",
        "materials_test = pd.read_csv(path + '/enWithoutMaterialData.csv')\n",
        "\n",
        "df = materials\n",
        "df.head()\n",
        "# df.info()\n",
        "# df.description \n",
        "# df.description + df.euralDescription\n"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reason</th>\n",
              "      <th>origin</th>\n",
              "      <th>color</th>\n",
              "      <th>state</th>\n",
              "      <th>size</th>\n",
              "      <th>consistency</th>\n",
              "      <th>otherCode</th>\n",
              "      <th>material4</th>\n",
              "      <th>material3</th>\n",
              "      <th>material2</th>\n",
              "      <th>material</th>\n",
              "      <th>mType</th>\n",
              "      <th>composite2</th>\n",
              "      <th>composite1</th>\n",
              "      <th>cType</th>\n",
              "      <th>indirectProduct</th>\n",
              "      <th>directProduct</th>\n",
              "      <th>pType</th>\n",
              "      <th>mixedOrPure</th>\n",
              "      <th>cleanOrDirty</th>\n",
              "      <th>euralDescription</th>\n",
              "      <th>euralCode</th>\n",
              "      <th>description</th>\n",
              "      <th>/0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>slurry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>oil</td>\n",
              "      <td>organic material</td>\n",
              "      <td>Soy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>dry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>dry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>material unsuitable for consumption or processing</td>\n",
              "      <td>20304</td>\n",
              "      <td>Soyadroes technically</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vast</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>wood</td>\n",
              "      <td>branches</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>wood</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>waste from forestry</td>\n",
              "      <td>20107</td>\n",
              "      <td>Branches</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vast</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cocoa</td>\n",
              "      <td>caps</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cocoa</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>material unsuitable for consumption or processing</td>\n",
              "      <td>20304</td>\n",
              "      <td>Cocoa shells</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>debris</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vast</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sand</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>debris</td>\n",
              "      <td>NaN</td>\n",
              "      <td>debris</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>mixtures of concrete, stones, tiles or ceramic...</td>\n",
              "      <td>170107</td>\n",
              "      <td>Debris with Sand</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vast</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>organic material</td>\n",
              "      <td>Soy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>organic material</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>material unsuitable for consumption or processing</td>\n",
              "      <td>20304</td>\n",
              "      <td>soya</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  reason origin color  ... euralCode            description  /0\n",
              "0    NaN    NaN   NaN  ...     20304  Soyadroes technically NaN\n",
              "1    NaN    NaN   NaN  ...     20107               Branches NaN\n",
              "2    NaN    NaN   NaN  ...     20304           Cocoa shells NaN\n",
              "3    NaN    NaN   NaN  ...    170107       Debris with Sand NaN\n",
              "4    NaN    NaN   NaN  ...     20304                   soya NaN\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPOLLyVRzcQ9",
        "colab_type": "text"
      },
      "source": [
        "###Tokening the Data With spaCy\n",
        "\n",
        "Now that we know what we’re working with, let’s create a custom tokenizer function using spaCy. We’ll use this function to automatically strip information we don’t need, like stopwords and punctuation, from each review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDWKUU8RvJz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "parser = English()\n",
        "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "stopwords = STOP_WORDS\n",
        "\n",
        "def spacy_tokenize(sentence):\n",
        "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
        "    sentence = sentence.strip().lower()\n",
        "    tokens = parser(sentence)\n",
        "\n",
        "    # Lemmatizing each token and converting each token into lowercase\n",
        "    tokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in tokens ]\n",
        "\n",
        "    # Removing stop words\n",
        "    tokens = [ word for word in mytokens if word not in stopwords and word not in punctuations ]\n",
        "\n",
        "    # return preprocessed list of tokens\n",
        "    return tokens\n"
      ],
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXxABNYI50mQ",
        "colab_type": "text"
      },
      "source": [
        "###Get all Nouns from description\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loGBEIWdab7V",
        "colab_type": "text"
      },
      "source": [
        "#### unique materials list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjQWe5qUaTsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. unique existing meterials list\n",
        "MATERIALS = [\n",
        "  'organic material',\n",
        "  'organic',\n",
        "  'polypropylene',\n",
        "  'wood',\n",
        "  'cocoa',\n",
        "  'sand',\n",
        "  'starch',\n",
        "  'water',\n",
        "  'grind',\n",
        "  'ceramics',\n",
        "  'collect',\n",
        "  'metal',\n",
        "  'plastic',\n",
        "  'plastics',\n",
        "  'soy',\n",
        "  'bentonite',\n",
        "  'dough',\n",
        "  'oil',\n",
        "  'oils',\n",
        "  'melamine',\n",
        "  'ground',\n",
        "  'know',\n",
        "  'most',\n",
        "  'pvc',\n",
        "  'fatty acids',\n",
        "  'pom',\n",
        "  'asbestos',\n",
        "  'cast',\n",
        "  'stones',\n",
        "  'hdpe',\n",
        "  'paper',\n",
        "  'snails',\n",
        "  'glass',\n",
        "  'ldpe',\n",
        "  'bold',\n",
        "  'pp',\n",
        "  'rvs',\n",
        "  'iron',\n",
        "  'stories',\n",
        "  'eps',\n",
        "  'right now',\n",
        "  'pet',\n",
        "  'sintels',\n",
        "  'minerals',\n",
        "  'beer',\n",
        "  'up',\n",
        "  'carton',\n",
        "  'section',\n",
        "  'molasses',\n",
        "  'tyleen',\n",
        "  'avi-bodemas',\n",
        "  'pc',\n",
        "  'pmma',\n",
        "  'carbon',\n",
        "  'bitumen',\n",
        "  'perlite',\n",
        "  'teer',\n",
        "  'resin',\n",
        "  'glass wool',\n",
        "  'aluminum',\n",
        "  'rock wool',\n",
        "  'wool',\n",
        "  'rubber',\n",
        "  'sugar',\n",
        "  'bread',\n",
        "  'pfos',\n",
        "  'optical fiber',\n",
        "  'insulation material',\n",
        "  'insulation',\n",
        "  'steel',\n",
        "  'dill',\n",
        "  'ps',\n",
        "  'on',\n",
        "  'compost',\n",
        "  'wine',\n",
        "  'turf',\n",
        "  'cork',\n",
        "  'foam rubber',\n",
        "  'cement',\n",
        "  'pa',\n",
        "  'nylon',\n",
        "  'messing',\n",
        "  'believe',\n",
        "  'zinc',\n",
        "  'non-iron',\n",
        "  'flint',\n",
        "  'pcfic',\n",
        "  'kwik',\n",
        "  'syrup',\n",
        "  'lime',\n",
        "  'solvents',\n",
        "  'zeolite',\n",
        "  'porcelain',\n",
        "  'polyester',\n",
        "  'snail wool',\n",
        "  'fly ash',\n",
        "  'beryllium',\n",
        "  'nickel',\n",
        "  'glycerine',\n",
        "  'sodium hypochlorite',\n",
        "  'acid',\n",
        "  'urea',\n",
        "  'cheese',\n",
        "  'dioxin',\n",
        "  'cyaniden',\n",
        "  'log',\n",
        "  'vocl',\n",
        "  'activated carbon',\n",
        "  'wrap',\n",
        "  'vinasse',\n",
        "  'shells',\n",
        "  'pcb',\n",
        "  'magnesium',\n",
        "  'nox',\n",
        "  'fipronil',\n",
        "  'koolas',\n",
        "  'fiber',\n",
        "  'dog',\n",
        "  'paraffin',\n",
        "  'styrene butadiene rubber',\n",
        "  'styrene',\n",
        "  'butadiene',\n",
        "  'cadmium',\n",
        "  'then',\n",
        "  'glycol',\n",
        "  'inorganic material',\n",
        "  'school',\n",
        "  'formaline',\n",
        "  'salt',\n",
        "  'salts',\n",
        "  'ocb',\n",
        "  'pak',\n",
        "  'mo',\n",
        "  'silicon',\n",
        "  'stone',\n",
        "  'chocolate',\n",
        "  'chrome',\n",
        "  'soil',\n",
        "  'soya',\n",
        "  'foil',\n",
        "  'concrete',\n",
        "  'breadcrumb',\n",
        "  'breadcrumbs',\n",
        "  'plaster',\n",
        "  'aw',\n",
        "  'concrete',\n",
        "]"
      ],
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVxMk48cauty",
        "colab_type": "text"
      },
      "source": [
        "#### extract unique materials "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgVYT1NI57qO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f736094b-f4da-46b2-f215-0ca6349abda7"
      },
      "source": [
        "import spacy\n",
        "import re\n",
        "import string\n",
        "\n",
        "parser = spacy.load('en_core_web_sm')\n",
        "\n",
        "def extract_materials(row):\n",
        "  sentence = str(df.iloc[row]['description'])\n",
        "  sentence = sentence.strip().lower()\n",
        "  sentence = re.sub(r'\\d+', '', sentence) # removes numbers \n",
        "  sentence = re.sub(r'[^\\w\\s]','',sentence) # removes punctuations\n",
        "\n",
        "  print('sentence----', sentence)\n",
        "  doc = parser(sentence)\n",
        "\n",
        "  \n",
        "  for np in doc.noun_chunks:\n",
        "    for token in np:\n",
        "      if token.pos_ is 'NOUN' or token.pos_ is 'PROPN':\n",
        "        if token.text in MATERIALS or token.lemma_ in MATERIALS:\n",
        "          print('rich mat:', np)\n",
        "\n",
        "\n",
        "  #only material noun:    \n",
        "  index = [1] # iterate through sentence once\n",
        "  for idxValue in index:\n",
        "    for token in doc:\n",
        "      # print(token, '--', token.pos_)\n",
        "      if token.pos_ is 'NOUN' or token.pos_ is 'PROPN' or token.pos_ is 'ADJ' or token.pos_ is 'INTJ':\n",
        "        if token.text in MATERIALS or token.lemma_ in MATERIALS:\n",
        "          print('material:',  token.text)\n",
        "          \n",
        "  print()\n",
        "\n",
        "extract_materials(919)\n",
        "extract_materials(929)\n",
        "extract_materials(939)\n",
        "extract_materials(949)"
      ],
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence---- rvs albermarle\n",
            "rich mat: rvs\n",
            "material: rvs\n",
            "\n",
            "sentence---- clean concrete debris\n",
            "material: concrete\n",
            "\n",
            "sentence---- bbk aw starting\n",
            "material: aw\n",
            "\n",
            "sentence---- land oude doelenkade  hoorn\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_5vbCettOKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "818ad968-859f-4ff7-d134-25b8576f9524"
      },
      "source": [
        "# Visualize Entities\n",
        "from spacy import displacy\n",
        "import IPython\n",
        "\n",
        "row = 33\n",
        "description = str(df.iloc[row]['description'])\n",
        "doc = parser(description)\n",
        "print('entities----', [(ent.text, ent.label_, spacy.explain(ent.label_)) for ent in doc.ents])\n",
        "print(spacy.explain('INTJ'))\n",
        "\n",
        "visualize = displacy.render(doc, style=\"ent\")\n",
        "\n",
        "IPython.display.HTML(visualize)\n",
        "\n"
      ],
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "entities---- [('melamine-urea / formalin co-polymer', 'ORG', 'Companies, agencies, institutions, etc.')]\n",
            "interjection\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    melamine-urea / formalin co-polymer\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 319
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj7q5mGz0V6Q",
        "colab_type": "text"
      },
      "source": [
        "###Vectorization Feature Engineering (TF-IDF) , Bag of Words and N-grams\n",
        "\n",
        "Classifying text we end up with text snippets with their respective labels. But in machine learning model we need to convert into numeric representation\n",
        "\n",
        "TF-IDF -Term Frequency-Inverse Document Frequency - simply a way of normalizing our Bag of Words(BoW) by looking at each word’s frequency in comparison to the document frequency.\n",
        "\n",
        "N-grams - combinations of adjacent words in a given text. For example \"who will win\"\n",
        "- when n = 1, becomes \"who\", \"will\", \"win\"\n",
        "- when n = 2 , becomes \"who will\", \"will win\" etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8vNowrk0WUW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "2fb187b8-61a6-4010-bf4b-26ec6786f19e"
      },
      "source": [
        "#bag of words vector\n",
        "bow_vector = CountVectorizer(tokenizer=spacy_tokenize, ngram_range=(1,1))\n",
        "print(bow_vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
            "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
            "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
            "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=<function spacy_tokenize at 0x7f5ebe885e18>,\n",
            "                vocabulary=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-bT6HzllahL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "4714b119-b5af-4c47-c2c9-20266c7c6b69"
      },
      "source": [
        "tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenize)\n",
        "print(tfidf_vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
            "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
            "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
            "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
            "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=<function spacy_tokenize at 0x7f5ebe885e18>,\n",
            "                use_idf=True, vocabulary=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYHmZbUqv_3i",
        "colab_type": "text"
      },
      "source": [
        "### Splitting The Data into Training and Validation Sets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d4AVLzEv_Cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['description'] # the features we want to analyze\n",
        "ylabels = df['material'] # the labels, or answers, we want to test against\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3)\n",
        "\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs546SLByRfT",
        "colab_type": "text"
      },
      "source": [
        "### Creating a Pipeline and Generating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0iorejbyVs6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "96a9162d-eedd-4337-8ab6-1f602573ef94"
      },
      "source": [
        "# Creating Logistic Regression Classifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "# Create pipeline using Bag of Words\n",
        "pipe = Pipeline([(\"cleaner\", predictors()),\n",
        "                 ('vectorizer', bow_vector),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# model generation\n",
        "pipe.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('cleaner', <__main__.predictors object at 0x7f5eb771e080>),\n",
              "                ('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 t...\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function spacy_tokenize at 0x7f5ebe885e18>,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzuGqju6zSjW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f5badf26-cea2-446d-cdfb-81d256d8c872"
      },
      "source": [
        "from sklearn import metrics\n",
        "row = 33\n",
        "# Predicting with a test dataset\n",
        "predicted = pipe.predict(X_test)\n",
        "\n",
        "\n",
        "print('material description was ----> ', X_test.iloc[row])\n",
        "print('material predicted is ----->', predicted[row])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "material description was ---->  BRAC ind reusable N building material\n",
            "material predicted is -----> organic material\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DkzvWsQ0fTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Model Accuracy\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, predicted ))\n",
        "print(\"Precision:\",metrics.precision_score(y_test, predicted, average='weighted'))\n",
        "print(\"Recall:\",metrics.recall_score(y_test, predicted, average='weighted'))\n",
        "\n",
        "\n",
        "print(metrics.classification_report(y_test, predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKZVwKfRB2_s",
        "colab_type": "text"
      },
      "source": [
        "### Plot the description and material Outcomes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80cYKSKZ6buv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# plot\n",
        "chosen_material = 'ground'\n",
        "\n",
        "\n",
        "data = df.loc[df.material ==chosen_material]\n",
        "sns.set_style('ticks')\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(1, 85)\n",
        "sns.regplot(x='material', y='description', data=data, ax=ax)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYdB-9vd_uT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}