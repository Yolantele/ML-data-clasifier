{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpaCy-ML-Classifier-for-Waste-Data-Augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN19plXYz48fxTLDk4aYVdP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yolantele/ML-data-clasifier/blob/master/SpaCy_ML_Classifier_for_Waste_Data_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "US3U82Q2Oq28",
        "colab_type": "text"
      },
      "source": [
        "####**SpaCy Data Classification POC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0MIMTSkPAN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GchVo49oPHvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "64a8e77a-4112-4550-f389-0441c971119e"
      },
      "source": [
        "# mount data from drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/My Drive/data/'\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTRIFjFaPbf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U spacy==2.2.2\n",
        "!pip install pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxLC2X13Qw7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "import pandas as pd\n",
        "from spacy.lang.en import English\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "\n",
        "\n",
        "# References:\n",
        "# https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/\n",
        "\n",
        "spacy.prefer_gpu()\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L324D-Gql23q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "02fac382-77b4-4554-bf79-d21815f659f9"
      },
      "source": [
        "materials = pd.read_csv(path + '/enMaterialData.csv')\n",
        "# or use test data frame where material field is empty\n",
        "materials_test = pd.read_csv(path + '/enWithoutMaterialData.csv')\n",
        "\n",
        "df = materials\n",
        "df.head()\n",
        "# df.info()\n",
        "# df.description + df.euralDescription\n",
        "# df.description + df.euralDescription\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reason</th>\n",
              "      <th>origin</th>\n",
              "      <th>color</th>\n",
              "      <th>state</th>\n",
              "      <th>size</th>\n",
              "      <th>consistency</th>\n",
              "      <th>otherCode</th>\n",
              "      <th>material4</th>\n",
              "      <th>material3</th>\n",
              "      <th>material2</th>\n",
              "      <th>material</th>\n",
              "      <th>mType</th>\n",
              "      <th>composite2</th>\n",
              "      <th>composite1</th>\n",
              "      <th>cType</th>\n",
              "      <th>indirectProduct</th>\n",
              "      <th>directProduct</th>\n",
              "      <th>pType</th>\n",
              "      <th>mixedOrPure</th>\n",
              "      <th>cleanOrDirty</th>\n",
              "      <th>euralDescription</th>\n",
              "      <th>euralCode</th>\n",
              "      <th>description</th>\n",
              "      <th>/0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>slurry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>oil</td>\n",
              "      <td>organic material</td>\n",
              "      <td>Soy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>dry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>dry</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>material unsuitable for consumption or processing</td>\n",
              "      <td>20304</td>\n",
              "      <td>Soyadroes technically</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vast</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>wood</td>\n",
              "      <td>branches</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>wood</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>waste from forestry</td>\n",
              "      <td>20107</td>\n",
              "      <td>Branches</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vast</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cocoa</td>\n",
              "      <td>caps</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cocoa</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>material unsuitable for consumption or processing</td>\n",
              "      <td>20304</td>\n",
              "      <td>Cocoa shells</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>debris</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vast</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sand</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>debris</td>\n",
              "      <td>NaN</td>\n",
              "      <td>debris</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>mixtures of concrete, stones, tiles or ceramic...</td>\n",
              "      <td>170107</td>\n",
              "      <td>Debris with Sand</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vast</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>organic material</td>\n",
              "      <td>Soy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>organic material</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>material unsuitable for consumption or processing</td>\n",
              "      <td>20304</td>\n",
              "      <td>soya</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  reason origin color  ... euralCode            description  /0\n",
              "0    NaN    NaN   NaN  ...     20304  Soyadroes technically NaN\n",
              "1    NaN    NaN   NaN  ...     20107               Branches NaN\n",
              "2    NaN    NaN   NaN  ...     20304           Cocoa shells NaN\n",
              "3    NaN    NaN   NaN  ...    170107       Debris with Sand NaN\n",
              "4    NaN    NaN   NaN  ...     20304                   soya NaN\n",
              "\n",
              "[5 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPOLLyVRzcQ9",
        "colab_type": "text"
      },
      "source": [
        "###Tokening the Data With spaCy\n",
        "\n",
        "Now that we know what we’re working with, let’s create a custom tokenizer function using spaCy. We’ll use this function to automatically strip information we don’t need, like stopwords and punctuation, from each review."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDWKUU8RvJz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "parser = English()\n",
        "\n",
        "def spacy_tokenize(sentence):\n",
        "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
        "    sentence = sentence.strip().lower()\n",
        "    mytokens = parser(sentence)\n",
        "\n",
        "    # Lemmatizing each token and converting each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "\n",
        "    # Removing stop words\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    # return preprocessed list of tokens\n",
        "    return mytokens\n"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj7q5mGz0V6Q",
        "colab_type": "text"
      },
      "source": [
        "###Vectorization Feature Engineering (TF-IDF) , Bag of Words and N-grams\n",
        "\n",
        "Classifying text we end up with text snippets with their respective labels. But in machine learning model we need to convert into numeric representation\n",
        "\n",
        "TF-IDF -Term Frequency-Inverse Document Frequency - simply a way of normalizing our Bag of Words(BoW) by looking at each word’s frequency in comparison to the document frequency.\n",
        "\n",
        "N-grams - combinations of adjacent words in a given text. For example \"who will win\"\n",
        "- when n = 1, becomes \"who\", \"will\", \"win\"\n",
        "- when n = 2 , becomes \"who will\", \"will win\" etc. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8vNowrk0WUW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "2fb187b8-61a6-4010-bf4b-26ec6786f19e"
      },
      "source": [
        "#bag of words vector\n",
        "bow_vector = CountVectorizer(tokenizer=spacy_tokenize, ngram_range=(1,1))\n",
        "print(bow_vector)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
            "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
            "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
            "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=<function spacy_tokenize at 0x7f5ebe885e18>,\n",
            "                vocabulary=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-bT6HzllahL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "4714b119-b5af-4c47-c2c9-20266c7c6b69"
      },
      "source": [
        "tfidf_vector = TfidfVectorizer(tokenizer=spacy_tokenize)\n",
        "print(tfidf_vector)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
            "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
            "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
            "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
            "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=<function spacy_tokenize at 0x7f5ebe885e18>,\n",
            "                use_idf=True, vocabulary=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYHmZbUqv_3i",
        "colab_type": "text"
      },
      "source": [
        "### Splitting The Data into Training and Validation Sets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d4AVLzEv_Cb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "f85cd6d0-61a8-4f17-f1dd-f9293f311649"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['description'] # the features we want to analyze\n",
        "ylabels = df['material'] # the labels, or answers, we want to test against\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3)\n",
        "\n",
        "print(X)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0                                   Soyadroes technically\n",
            "1                                                Branches\n",
            "2                                            Cocoa shells\n",
            "3                                        Debris with Sand\n",
            "4                                                    soya\n",
            "                              ...                        \n",
            "2115                                          LDPE - 98:2\n",
            "2116    hollow variegated glass, route collection fire...\n",
            "2117                  Soil mixed with contaminated stones\n",
            "2118    Stainless steel, Motors, Refiner, Tin / Lead, ...\n",
            "2119     soil / gravel / stones / cloths oil contaminated\n",
            "Name: description, Length: 2120, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs546SLByRfT",
        "colab_type": "text"
      },
      "source": [
        "### Creating a Pipeline and Generating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0iorejbyVs6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "96a9162d-eedd-4337-8ab6-1f602573ef94"
      },
      "source": [
        "# Creating Logistic Regression Classifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "classifier = LogisticRegression()\n",
        "\n",
        "# Create pipeline using Bag of Words\n",
        "pipe = Pipeline([(\"cleaner\", predictors()),\n",
        "                 ('vectorizer', bow_vector),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# model generation\n",
        "pipe.fit(X_train,y_train)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('cleaner', <__main__.predictors object at 0x7f5eb771e080>),\n",
              "                ('vectorizer',\n",
              "                 CountVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
              "                                 input='content', lowercase=True, max_df=1.0,\n",
              "                                 max_features=None, min_df=1,\n",
              "                                 ngram_range=(1, 1), preprocessor=None,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 t...\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=<function spacy_tokenize at 0x7f5ebe885e18>,\n",
              "                                 vocabulary=None)),\n",
              "                ('classifier',\n",
              "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                    fit_intercept=True, intercept_scaling=1,\n",
              "                                    l1_ratio=None, max_iter=100,\n",
              "                                    multi_class='auto', n_jobs=None,\n",
              "                                    penalty='l2', random_state=None,\n",
              "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                                    warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzuGqju6zSjW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f5badf26-cea2-446d-cdfb-81d256d8c872"
      },
      "source": [
        "from sklearn import metrics\n",
        "row = 33\n",
        "# Predicting with a test dataset\n",
        "predicted = pipe.predict(X_test)\n",
        "\n",
        "\n",
        "print('material description was ----> ', X_test.iloc[row])\n",
        "print('material predicted is ----->', predicted[row])"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "material description was ---->  BRAC ind reusable N building material\n",
            "material predicted is -----> organic material\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DkzvWsQ0fTf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5d18297b-bfbd-463e-9dee-e8429cbc591a"
      },
      "source": [
        "\n",
        "# Model Accuracy\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, predicted ))\n",
        "print(\"Precision:\",metrics.precision_score(y_test, predicted, average='weighted'))\n",
        "print(\"Recall:\",metrics.recall_score(y_test, predicted, average='weighted'))\n",
        "\n",
        "\n",
        "print(metrics.classification_report(y_test, predicted))"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8286163522012578\n",
            "Precision: 0.8213044253850307\n",
            "Recall: 0.8286163522012578\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "                EPS       1.00      0.83      0.91         6\n",
            "              Glass       0.94      0.94      0.94        16\n",
            "               HDPE       1.00      0.50      0.67         2\n",
            "               LDPE       1.00      1.00      1.00         9\n",
            "                 ON       1.00      1.00      1.00         2\n",
            "                 PC       0.00      0.00      0.00         2\n",
            "                PET       1.00      1.00      1.00         1\n",
            "               PFOS       0.00      0.00      0.00         1\n",
            "               PMMA       0.00      0.00      0.00         3\n",
            "                 PP       0.75      1.00      0.86         3\n",
            "                 PS       1.00      0.67      0.80         3\n",
            "                PVC       1.00      0.67      0.80         3\n",
            "            Perlite       0.00      0.00      0.00         1\n",
            "                RVS       0.33      0.33      0.33         3\n",
            "           aluminum       0.00      0.00      0.00         5\n",
            "           asbestos       1.00      0.95      0.98        22\n",
            "               beer       0.00      0.00      0.00         1\n",
            "          bentonite       1.00      0.25      0.40         4\n",
            "          beryllium       0.00      0.00      0.00         1\n",
            "            bitumen       1.00      0.67      0.80         3\n",
            "               bold       1.00      0.67      0.80         3\n",
            "              bread       0.00      0.00      0.00         1\n",
            "             carton       1.00      0.40      0.57         5\n",
            "               cast       1.00      0.71      0.83         7\n",
            "             cement       0.00      0.00      0.00         1\n",
            "   ceramic material       0.00      0.00      0.00         2\n",
            "              cocoa       0.80      0.57      0.67         7\n",
            "            collect       1.00      1.00      1.00         1\n",
            "               dill       1.00      1.00      1.00         2\n",
            "              dough       0.00      0.00      0.00         1\n",
            "        fatty acids       1.00      1.00      1.00         1\n",
            "              grind       0.91      0.90      0.91        59\n",
            "             ground       0.95      0.97      0.96       160\n",
            "insulation material       1.00      1.00      1.00         4\n",
            "               iron       0.50      1.00      0.67         1\n",
            "               know       0.94      0.77      0.85        22\n",
            "           lavaliet       0.00      0.00      0.00         1\n",
            "            messing       0.00      0.00      0.00         1\n",
            "              metal       0.75      0.75      0.75         4\n",
            "           molasses       0.00      0.00      0.00         1\n",
            "               most       0.00      0.00      0.00         1\n",
            "              nylon       0.00      0.00      0.00         1\n",
            "                oil       1.00      1.00      1.00         6\n",
            "   organic material       0.52      0.99      0.68        87\n",
            "              paper       1.00      0.83      0.91        18\n",
            "            plastic       0.84      0.84      0.84        19\n",
            "          porcelain       0.00      0.00      0.00         1\n",
            "                pvc       0.00      0.00      0.00         1\n",
            "             rubber       1.00      0.33      0.50         3\n",
            "                rvs       0.00      0.00      0.00         1\n",
            "               sand       0.96      0.75      0.84        32\n",
            "            sintels       0.00      0.00      0.00         5\n",
            "             snails       0.90      0.82      0.86        11\n",
            "              steel       0.00      0.00      0.00         1\n",
            "             stones       0.00      0.00      0.00         1\n",
            "            stories       0.00      0.00      0.00         3\n",
            "              sugar       0.00      0.00      0.00         1\n",
            "              syrup       0.00      0.00      0.00         1\n",
            "               teer       1.00      0.33      0.50         3\n",
            "             tyleen       0.00      0.00      0.00         1\n",
            "              water       0.60      0.43      0.50         7\n",
            "               wood       0.98      0.91      0.94        56\n",
            "            zeolite       0.00      0.00      0.00         1\n",
            "\n",
            "           accuracy                           0.83       636\n",
            "          macro avg       0.52      0.44      0.46       636\n",
            "       weighted avg       0.82      0.83      0.81       636\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKZVwKfRB2_s",
        "colab_type": "text"
      },
      "source": [
        "### Plot the description and material Outcomes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80cYKSKZ6buv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# plot\n",
        "chosen_material = 'ground'\n",
        "\n",
        "\n",
        "data = df.loc[df.material ==chosen_material]\n",
        "sns.set_style('ticks')\n",
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(1, 85)\n",
        "sns.regplot(x='material', y='description', data=data, ax=ax)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYdB-9vd_uT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}